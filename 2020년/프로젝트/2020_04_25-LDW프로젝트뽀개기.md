#### Lane Departure Warning 뽀개기_1



애증의 lane detection.... 해외 유튜브 방송에 관련 소개도 많고, udacity 에 강의도 잘 되어 있어 관련 소스를 찾는 건 어렵지 않다. 하지만 왜!!! 한글로 정리된 내용은 없는지ㅜㅜ 어려워서 내가 정리하는 lane departure warning 메모.



#### 뽀갤 소스는 구함

여러 소스들을 검색하면서 내가 찾은 것은 https://github.com/JunshengFu/driving-lane-departure-warning, 현재 스웨덴의 Zenuity 에서 자율주행 엔지니어로 일하고 계시는 Junsheng Fu씨, 잘 쓰겠습니다. 이 분 깃헙가보면 보물창고다. 정말 감사하신 분...!!!



#### 환경 설정

소스 클로닝 후, conda 를 이용하여 개발환경을 셋팅한다.

```shell
conda env create -f environment-gpu.yml
```

리눅스 환경에서 설정된 프로젝트인지 윈도우에서 하려니 'conflict error' 가 발생했다. 처음엔 뭐가 문제인지 이리 저리 살펴보다가 리눅스 환경에서 하니 잘 된다... 윈도우즈에선 필요하다고 하는 거 잘 받아서 셋팅하자. 잘 되더라.



#### python 버젼 차이로 생기는 에러 몇몇 고치기

> **TypeError: slice indices must be integers or None or have an __index__ method**
>
> 나눈 값이 정수가 아니라서 생기는 에러로, / 대신 // 로 수정. (이 전 버젼에서는 / 로 나누어도 정수 반환)
>
> 그 외에 float라 생기는 몇몇 문제들을 고치고 돌리면, 코드는 잘 돌아간다.



#### 개요

먼저 Junsheng Fu씨의 readme.md github 설명을 읽어보며 프로젝트를 이해해본다. 이 프로젝트는 총 6개의 파일 및 폴더로 이루어져있다.

- calibration.py : 카메라를 보정하는 소스와 보정 결과 저장.
- main.py : 2가지 데모에 대한 메인 코드 (1 : 스틸샷(이미지) 한 장에 대한 LDW 결과를 matplotlib 을 통해 보여줌 / 2 : moviepy를 이용하여 LDW 결과를 동영상에 저장하여 반환)
- lane.py : lane class, lane 을 인지하고 표시하는 대부분의 역할이 들어있겟죠?
- camera_cal : 카메라 보정 결과와 카메라 보정에 필요한 사진들
- examples : 샘플 이미지 및 비디오
- enviroment-gpu.yml : GPU 환경에 필요한 환경 설정 파일



##### 소스 어떻게 돌리냐?

demo 돌리고 싶으면, 간단하게 요렇게 :

```shell
python main.py
```

내 카메라로 셋팅해서 해보고 싶으면 캘리브레이션 필요! 이렇게 :

```shell
python calibration.py
```



#### 단계별로 살펴보기

1. Camera calibration
   - 카메라 보정을 위한 chessboard 이미지셋을 모은다.
   - Camera calibration matrix / distortion coefficients 계산
   - 들어오는 이미지에 distortion correction 적용
2. Lane detection / tracking
   - 색상 변환 (color transform), 그래디언트 (Gradient) 등을 사용하여 이진 이미지 만들기
   - Perspective Transform 을 이용하여 이미지 정 변환 (bird-eye view 만들기)
   - 차선 바운더리 영역을 찾기 위해 차선을 인지 및 추적
3. Lane status anlysis (차선 상태 분석)
   - 차선 곡률 (curvature of the lane) 구하기
   - Center-line offset 구하기 (예상되는 센터값에서 얼마나 떨어져있는지?)
4. Lane augumentation
   - 인지한 차선 바운더리를 다시 오리지널 이미지에 입혀 되돌린다.
   - 이미지에 도로 상태 표시 출력.

---

#### Camera calibration

**Camera calibration matrix / distortion coefficients 계산하기**

카메라 캘리브레이션에 대한 내용은 모두 *calibration.py* 에 있다. 먼저 오브젝트 포인트(Object point) 를 준비하는데 이 포인트는 chessboard 판의 코너 점의 월드 좌표가 된다. 여기서 체스보드가 z=0 으로 (x,y) 평면에 고정되어 있다고 가정하면, 오브젝트 포인트들은 각 보정 이미지와 동일하다. 따라서 ``objp`` 는 복사된 좌표의 배열이며, 테스트 이미지에서 모든 체스판 모서리를 성공적으로 감지할 때마다 ``objpoints``는 추가된다. ``imgpoint``에는 체스보드 디텍션이 성공함에 따라 이미지 평면상의 (x,y) 픽셀좌표값이 저장된다.

![undist_example.jpg](https://github.com/JunshengFu/driving-lane-departure-warning/blob/master/examples/undist_example.jpg?raw=true)

*읽어도 무슨 말인지 이해가 안 된다. 코드 설명이니 당연하다. calibration.py 코드를 보면서 이해해보자*





---







##### 한 장씩 lane detection 처리

```python
import os
from lane import *
from moviepy.editor import *
from natsort import natsorted, ns

if __name__ == '__main__' :
    flie_list = natsorted(os.listdir('test_pic/test_images/'), key=lamdba y: y.lower())
    
    for imagepath in file_list:
        img = cv2.imread('test_pic/' + imagepath)
        img_aug = process_frame(img)
        
        cv2.imwrite('test_pic/aug_images/' + imagepath + '.jpg', img_aug)
```
